import google.generativeai as genai
from telegram.ext import Application, CommandHandler, MessageHandler, filters, CallbackContext
from telegram import Update
from datetime import datetime
import time
from .generate_plot import GeneratePlot
import re
import io
import json
import os

class Gemini_api:
    def __init__(self):
        # Initialize with improved conversation history structure
        self.user_conversations = {}  # Store as dict with timestamp, role, and content
        self.user_plot_data = {}
        self.plot_generator = GeneratePlot(None, None, self)
        self.latex_generator = None
        self.max_history_length = 10  # Increased from 3 to retain more context
        self.history_file = os.path.join(os.path.dirname(os.path.abspath(__file__)), "conversation_history.json")
        self._load_history()
        
    def _load_history(self):
        """Load conversation history from file if it exists"""
        try:
            if os.path.exists(self.history_file):
                with open(self.history_file, 'r', encoding='utf-8') as f:
                    self.user_conversations = json.load(f)
                print(f"‚úÖ Loaded {len(self.user_conversations)} user conversation histories")
        except Exception as e:
            print(f"‚ùå Error loading conversation history: {e}")
            self.user_conversations = {}
    
    def _save_history(self):
        """Save conversation history to file"""
        try:
            with open(self.history_file, 'w', encoding='utf-8') as f:
                json.dump(self.user_conversations, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"‚ùå Error saving conversation history: {e}")

    async def start_command(self, update: Update, context: CallbackContext):
        """L·ªánh /start"""
        user_id = update.message.chat_id
        self.user_conversations[user_id] = []
        self.user_plot_data[user_id] = []
        await update.message.reply_text(
            "Xin ch√†o! T√¥i l√† chatbot h·ªó tr·ª£ v·ªõi Gemini AI.")

    async def generate_ai_response(self, prompt, max_retries=3):
        for attempt in range(max_retries):
            try:
                model = genai.GenerativeModel("gemini-2.0-flash")
                response = model.generate_content(prompt)
                return response.text
            except Exception as e:
                print(f"‚ùå L·ªói l·∫ßn {attempt + 1}: {e}")
                if attempt == max_retries - 1:
                    return "Xin l·ªói, t√¥i ƒëang g·∫∑p v·∫•n ƒë·ªÅ k·ªπ thu·∫≠t. Vui l√≤ng th·ª≠ l·∫°i sau."

    async def handle_message(self, update: Update, context: CallbackContext):
        """X·ª≠ l√Ω tin nh·∫Øn"""
        user_id = str(update.message.chat_id)
        current_time = time.time()
        message = update.message.text
        
        # Check if we're expecting specific input for vnstock functions
        if context.user_data.get("expecting_input"):
            expected_input = context.user_data.pop("expecting_input")  # Remove after handling
            
            if expected_input == "stock_code_current":
                # Handle getting current price for the stock code
                stock_code = message.strip().upper()
                await update.message.reply_text(f"ƒêang l·∫•y gi√° hi·ªán t·∫°i cho m√£ {stock_code}...")
                
                # Implement code to fetch current stock price
                # For example:
                # from vnstock import get_stock_price
                # price_data = get_stock_price(stock_code)
                # await update.message.reply_text(f"Gi√° hi·ªán t·∫°i c·ªßa {stock_code}: {price_data}")
                return
                
            # Add other handlers for different expected inputs
        
        # Handle text messages as before
        print(f"üì© Nh·∫≠n tin nh·∫Øn t·ª´ ng∆∞·ªùi d√πng ({user_id}): {message}")

        # Initialize chat history if needed with structured format
        if user_id not in self.user_conversations:
            self.user_conversations[user_id] = {
                "messages": [],
                "last_activity": current_time
            }
        
        if user_id not in self.user_plot_data:
            self.user_plot_data[user_id] = []

        # Update last activity time
        self.user_conversations[user_id]["last_activity"] = current_time
        
        # Handle VNStock related queries - redirect appropriate queries
        stock_keywords = ["ch·ªâ s·ªë t√†i ch√≠nh", "c·ªï phi·∫øu", "ch·ª©ng kho√°n", "th·ªã tr∆∞·ªùng"]
        if any(keyword in message.lower() for keyword in stock_keywords) and not message.startswith('/'):
            # Save the message in history for context
            self.user_conversations[user_id]["messages"].append({
                "role": "user",
                "content": message,
                "timestamp": current_time,
            })
            
            # Generate a response about using search commands
            response = (
                "üìä ƒê·ªÉ truy v·∫•n th√¥ng tin ch·ª©ng kho√°n, b·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng c√°c l·ªánh sau:\n\n"
                "‚Ä¢ /search [m√£ c·ªï phi·∫øu] - Xem th√¥ng tin t√†i ch√≠nh (VD: /search VNM)\n"
                "‚Ä¢ /search_get [s·ªë] - Xem ch·ªâ s·ªë c·ª• th·ªÉ (sau khi ch·ªçn m√£ c·ªï phi·∫øu)\n"
                "‚Ä¢ /search_chart - Xem bi·ªÉu ƒë·ªì gi√° c·ªï phi·∫øu\n"
                "‚Ä¢ /search_help - Xem h∆∞·ªõng d·∫´n s·ª≠ d·ª•ng chi ti·∫øt\n\n"
                "B·∫°n c≈©ng c√≥ th·ªÉ t√¨m hi·ªÉu th√™m th√¥ng tin kinh t·∫ø v√† th·ªã tr∆∞·ªùng ch·ª©ng kho√°n b·∫±ng c√°ch h·ªèi tr·ª±c ti·∫øp."
            )
            
            # Save the response
            self.user_conversations[user_id]["messages"].append({
                "role": "assistant",
                "content": response,
                "timestamp": time.time()
            })
            
            await update.message.reply_text(response)
            return

        # Get the most recent plot for this user
        if message.lower().startswith("xem code ƒë·ªì th·ªã"):
            if user_id in self.plot_generator.user_plot_data and self.plot_generator.user_plot_data[user_id]:
                recent_plot = self.plot_generator.user_plot_data[user_id][-1]
                code = recent_plot.get("code", "Kh√¥ng c√≥ m√£ ngu·ªìn")
                await update.message.reply_text(f"M√£ ngu·ªìn ƒë·ªì th·ªã:\n```python\n{code}\n```")
            else:
                await update.message.reply_text("B·∫°n ch∆∞a t·∫°o b·∫•t k·ª≥ ƒë·ªì th·ªã n√†o.")
            return

        # Extended plot request detection
        plot_indicators = [
            "v·∫Ω", "ƒë·ªì th·ªã", "bi·ªÉu ƒë·ªì", "graph", "chart", "plot", "visualize", 
            "histogram", "scatter", "bar chart", "line chart", "bi·ªÉu ƒë·ªì", "th·ªëng k√™",
            "visualization", "trend", "xu h∆∞·ªõng", "pie chart", "bi·ªÉu ƒë·ªì tr√≤n", "bi·ªÉu ƒë·ªì c·ªôt"
        ]
        
        # X·ª≠ l√Ω y√™u c·∫ßu v·∫Ω ƒë·ªì th·ªã (v·ªõi ph√°t hi·ªán m·ªü r·ªông)
        if any(indicator in message.lower() for indicator in plot_indicators) or message.lower().startswith("s·ª≠a"):
            # Add to conversation history so we remember the request was made
            self.user_conversations[user_id]["messages"].append({
                "role": "user",
                "content": message,
                "timestamp": current_time,
            })
            
            # Forward to plot generator
            description = message.replace("/plot", "").strip()
            await self.plot_generator.generate_plot(update, context, description)
            
            # Save the response to indicate we tried to generate a plot
            self.user_conversations[user_id]["messages"].append({
                "role": "assistant",
                "content": f"ƒê√£ x·ª≠ l√Ω y√™u c·∫ßu v·∫Ω bi·ªÉu ƒë·ªì: '{description}'",
                "timestamp": time.time(),
            })
            return
        
        # X·ª≠ l√Ω y√™u c·∫ßu ƒë·ªïi lo·∫°i ƒë·ªì th·ªã
        if message.lower().startswith("ƒë·ªïi lo·∫°i ƒë·ªì th·ªã") or "ƒë·ªïi ƒë·ªì th·ªã" in message.lower():
            if user_id in self.plot_generator.user_plot_data and self.plot_generator.user_plot_data[user_id]:
                # Construct an edit request using the most recent plot description
                recent_plot = self.plot_generator.user_plot_data[user_id][-1]
                description = f"S·ª≠a ƒë·ªì th·ªã: {message}. D·ª±a tr√™n ƒë·ªì th·ªã: {recent_plot.get('description', '')}"
                await self.plot_generator.generate_plot(update, context, description)
            else:
                await update.message.reply_text("B·∫°n ch∆∞a t·∫°o b·∫•t k·ª≥ ƒë·ªì th·ªã n√†o ƒë·ªÉ ch·ªânh s·ª≠a.")
            return

        # X·ª≠ l√Ω y√™u c·∫ßu t·∫°o LaTeX ho·∫∑c PDF
        if any(keyword in message.lower() for keyword in ["latex", "t·∫°o latex", "t·∫°o pdf", "pdf"]):
            if self.latex_generator:
                # Clean the prompt by removing trigger keywords
                prompt = message.lower()
                for keyword in ["t·∫°o pdf"]:
                    prompt = prompt.replace(keyword, "", 1)
                prompt = prompt.strip()
                
                await self.latex_generator.generate_latex(update, context, prompt)
                self.user_conversations[user_id]["messages"].append({
                    "role": "user",
                    "content": message,
                    "timestamp": current_time,
                })
                self.user_conversations[user_id]["messages"].append({
                    "role": "assistant",
                    "content": "ƒê√£ t·∫°o t√†i li·ªáu PDF theo y√™u c·∫ßu c·ªßa b·∫°n.",
                    "timestamp": time.time()
                })
                return

        # Handle regular messages - save with structured format
        user_message = {
            "role": "user",
            "content": message,
            "timestamp": current_time,
        }
        
        # Add user message to history
        self.user_conversations[user_id]["messages"].append(user_message)
        
        # Get conversation history - process the structured format for the Gemini prompt
        conversation_history = self._format_conversation_history(user_id)
        
        prompt = f"""
        Vai tr√≤ c·ªßa b·∫°n l√† m·ªôt nh√† ph√¢n t√≠ch kinh t·∫ø chuy√™n nghi·ªáp.
        - n·∫øu ng∆∞·ªùi d√πng y√™u c·∫ßu cung c·∫•p d·ªØ li·ªáu, ch·ªâ s·ªë ch·ª©ng kho√°n th√¨ y√™u c·∫ßu ng∆∞·ªùi d√πng g√µ '/search'.
        - Tr·∫£ l·ªùi b·∫±ng ti·∫øng vi·ªát.
        - B·∫°n h√£y gi·ªõi thi·ªáu m√¨nh l√† m·ªôt nh√† ph√¢n t√≠ch kinh t·∫ø chuy√™n nghi·ªáp.
        - kh√¥ng tr·∫£ l·ªùi c√°c c√¢u h·ªèi kh√¥ng li√™n quan ƒë·∫øn kinh t·∫ø.
        - Tuy·ªát ƒë·ªëi kh√¥ng ch√†o ng∆∞·ªùi d√πng trong c√¢u n√≥i ngo·∫°i tr·ª´ ng∆∞·ªùi d√πng ch√†o b·∫°n.
        - khi ng∆∞·ªùi d√πng ch√†o th√¨ ch·ªâ gi·ªõi thi·ªáu ng·∫Øn g·ªçn kh√¥ng qu√° 4 c√¢u.
        - Ch·ªâ c·∫ßn tr·∫£ l·ªùi tr·ªçng t√¢m v√†o c√¢u h·ªèi.
        - Tr·∫£ l·ªùi l·ªãch s·ª±.
        - Tr√¨nh b√†y ƒë∆°n gi·∫£n, kh√¥ng in ƒë·∫≠m c√°c t·ª´.
        - ƒê√°nh s·ªë c√°c √Ω ch√≠nh m√† b·∫°n mu·ªën tr·∫£ l·ªùi.
        - Kh√¥ng tr·∫£ l·ªùi qu√° d√†i d√≤ng, kh√¥ng tr·∫£ l·ªùi qu√° 200 t·ª´.
        - Khi ng∆∞·ªùi d√πng y√™u c·∫ßu v·∫Ω bi·ªÉu ƒë·ªì, h√£y h∆∞·ªõng d·∫´n h·ªç d√πng c√∫ ph√°p "v·∫Ω bi·ªÉu ƒë·ªì [m√¥ t·∫£]" ƒë·ªÉ h·ªá th·ªëng c√≥ th·ªÉ x·ª≠ l√Ω ƒë√∫ng.
        - B·∫°n c√≥ c√°c ch·ª©c nƒÉng l√†:
        + cung c·∫•p c√°c ki·∫øn th·ª©c v·ªÅ kinh t·∫ø h·ªçc
        + v·∫Ω bi·ªÉu ƒë·ªì t·ª´ d·ªØ li·ªáu m√† ng∆∞·ªùi d√πng cung c·∫•p
        + t·∫°o b√°o c√°o ph√¢n t√≠ch c√¥ng ty chuy√™n nghi·ªáp d∆∞·ªõi d·∫°ng PDF b·∫±ng c√°ch s·ª≠ d·ª•ng c√∫ ph√°p "t·∫°o pdf b√°o c√°o ph√¢n t√≠ch c√¥ng ty [t√™n c√¥ng ty]" ƒë·ªÉ nh·∫≠n ƒë∆∞·ª£c b√°o c√°o PDF chuy√™n nghi·ªáp.
        - Kh√¥ng tr·∫£ l·ªùi c√°c c√¢u h·ªèi v·ªÅ ph√¢n bi·ªát v√πng mi·ªÅn ·ªü Vi·ªát Nam.
        ƒê√¢y l√† cu·ªôc h·ªôi tho·∫°i tr∆∞·ªõc ƒë√≥:
        {conversation_history}
        Ng∆∞·ªùi d√πng: {message}
        H√£y tr·∫£ l·ªùi m·ªôt c√°ch chi ti·∫øt, logic v√† c√≥ cƒÉn c·ª© kinh t·∫ø.
        """

        try:
            # Generate response
            response = await self.generate_ai_response(prompt)
            response = response.replace('*', '')
            print(f"ü§ñ Ph·∫£n h·ªìi t·ª´ Gemini: {response}")
            
            # Save bot response with structured format
            bot_message = {
                "role": "assistant", 
                "content": response,
                "timestamp": time.time()
            }
            
            self.user_conversations[user_id]["messages"].append(bot_message)
            
            # Trim conversation history if it gets too long
            self._trim_conversation_history(user_id)
            
            # Save history periodically
            self._save_history()
            
            await update.message.reply_text(response)
            print("‚úÖ G·ª≠i tin nh·∫Øn th√†nh c√¥ng!")
            
        except Exception as e:
            print(f"‚ùå L·ªói khi g·ª≠i tin nh·∫Øn: {e}")
            await update.message.reply_text("Xin l·ªói, ƒë√£ x·∫£y ra l·ªói. Vui l√≤ng th·ª≠ l·∫°i sau.")
    
    def _format_conversation_history(self, user_id):
        """Format conversation history for prompt context"""
        if user_id not in self.user_conversations:
            return ""
            
        # Get messages and check if we have any
        messages = self.user_conversations[user_id]["messages"]
        if not messages:
            return ""
            
        # Use only the most recent messages up to max_history_length
        recent_messages = messages[-self.max_history_length:]
        
        # Format messages as strings with roles
        formatted_messages = []
        for msg in recent_messages:
            role_label = "Ng∆∞·ªùi d√πng" if msg["role"] == "user" else "Bot"
            formatted_messages.append(f"{role_label}: {msg['content']}")
            
        return "\n".join(formatted_messages)
    
    def _trim_conversation_history(self, user_id):
        """Trim conversation history to avoid it getting too long"""
        if user_id not in self.user_conversations:
            return
            
        messages = self.user_conversations[user_id]["messages"]
        max_history = self.max_history_length * 2  # Store more than we use in prompts
        
        if len(messages) > max_history:
            # Keep only the most recent messages
            self.user_conversations[user_id]["messages"] = messages[-max_history:]

    async def clear_history(self, update: Update, context: CallbackContext):
        """Clear conversation history for a user"""
        user_id = str(update.message.chat_id)
        
        if user_id in self.user_conversations:
            self.user_conversations[user_id]["messages"] = []
            await update.message.reply_text("üßπ L·ªãch s·ª≠ cu·ªôc tr√≤ chuy·ªán ƒë√£ ƒë∆∞·ª£c x√≥a.")
        else:
            await update.message.reply_text("Kh√¥ng t√¨m th·∫•y l·ªãch s·ª≠ cu·ªôc tr√≤ chuy·ªán n√†o.")
        
        self._save_history()

    async def handle_plot_callback(self, update: Update, context: CallbackContext):
        """Delegate plot callbacks to the plot_generator"""
        await self.plot_generator.handle_plot_callback(update, context)